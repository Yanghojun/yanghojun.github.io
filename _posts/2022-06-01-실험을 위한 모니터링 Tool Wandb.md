---
layout: article
title:  "ì‹¤í—˜ì„ ìœ„í•œ ëª¨ë‹ˆí„°ë§ Tool Wandb"
category: [Pytorch] 
tag: [wandb, tensorboard, monitoring]
permalink: /Wandb/
show_author_profile: true
aside:
    toc: true
sidebar:
    nav: "study-nav"
---

# Wandb-Pytorch ì—°ê³„

[wandb ë¸”ë¡œê·¸ ìì²´ í¬ìŠ¤íŠ¸ì´ë©°, ì „ì²´ì ìœ¼ë¡œ ê°œë…ì„ ì¡ì•„ì¤Œ](https://wandb.ai/wandb_fc/korean/reports/Weights-Biases-Data-Science---Vmlldzo4MDEwNzc)  
[ì—¬ê¸° ì‚¬ì´íŠ¸ ê¼­ í•œë²ˆ ë³´ì!. Gradient ì–´ë–»ê²Œ í™œìš©í•˜ë©´ ì¢‹ì„ì§€ ì•Œë ¤ì¤Œ](https://89douner.tistory.com/313)  
[ì—¬ê¸°ëŠ” wandb ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•´ì¤€ ì‚¬ì´íŠ¸](https://pebpung.github.io/wandb/2021/10/06/WandB-1.html)

## Reproductibility(ì¬í˜„ì„±)ì„ ë†’ì´ê¸° ìœ„í•œ ì½”ë“œ

- mnist datasetë„ ì—¬ê¸°ì„œ ë°›ìŒ


```python
import os
import random

import numpy as np
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from tqdm.notebook import tqdm

torch.backends.cudnn.deterministic = True       # ì¬í˜„ì„±(Reproductibility)ì„ ìœ„í•¨. í•™ìŠµí•  ë•Œ ë§ˆë‹¤ ê²°ê³¼ ë‹¬ë¼ì§€ëŠ”ê²ƒ ë°©ì§€
random.seed(hash("setting random seeds") % 2**32 - 1)
np.random.seed(hash("improves reproducibility") % 2**32 - 1)
torch.manual_seed(hash("by removing stochasticity") % 2**32 - 1)        # torch.rand(), torch.randn(), torch.randint(), torch.randperm() ì— ì˜í–¥ì„ ì¤Œ
torch.cuda.manual_seed_all(hash("so runs are repeatable") % 2**32 - 1)  # gpu ëœë¤ì‹œë“œ ì´ˆê¸°í™”ì¸ë° multi gpuê¹Œì§€ ê³ ë ¤í•œê²ƒ

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
torchvision.datasets.MNIST.mirrors = [mirror for mirror in torchvision.datasets.MNIST.mirrors if not mirror.startswith("http://yann.lecun.com")]
```

## Quick start

- ë”¥ëŸ¬ë‹ ëª¨ë¸ ì´ˆê¸° ì„¤ì •ì— ë§ì´ ìì£¼ ì“°ì´ëŠ” yaml file, config fileë“± ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì´ˆê¸° í™˜ê²½ì…‹íŒ…ì´ ê°€ëŠ¥í•˜ë©° íŠœí† ë¦¬ì–¼ì—ì„œëŠ” Dictionary í˜•íƒœë¡œ í™˜ê²½ì…‹íŒ…ì„ ì§„í–‰
- wandbì— ì“°ì´ì§€ëŠ” ì•Šì§€ë§Œ ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ ì´ˆê¸° ëª¨ë¸ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ë¥¼ ì§€ì •í•´ì£¼ëŠ”ê²ƒì´ ê°œë°œí•  ë•Œ ì¢‹ìŒ


```python
config = dict(
    epochs=5,
    classes=10,
    kernels=[16, 32],
    batch_size=128,
    learning_rate=0.005,
    dataset="MNIST",
    architecture="CNN")
```

### wandb.login

> wandb í™ˆí˜ì´ì§€ì— íšŒì›ê°€ì… í›„ API í‚¤ë¥¼ ë°œê¸‰ë°›ëŠ”ë‹¤.


```python
import wandb

wandb.login()       # ì£¼í”¼í„° ë…¸íŠ¸ë¶ìœ¼ë¡œ ë°œê¸‰ë°›ì€ í‚¤ ì…ë ¥
```

    Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.
    [34m[1mwandb[0m: Currently logged in as: [33mjavis-team[0m (use `wandb login --relogin` to force relogin)
    




    True


### wandb.init

- wandbë¥¼ ì‹¤í–‰ì‹œí‚´. ì–´ë–¤ Repositoryì—ì„œ ì‹¤í–‰ì‹œí‚¬ì§€, ì–´ë–¤ í•­ëª©ë“¤ì„ tracking í•  ì§€ ë“±ì˜ ì´ˆê¸°í™” ë‹´ë‹¹
- ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” íŒŒë¼ë¯¸í„°
  - `project:(str, optional)`: runí•  Repository ì´ë¦„
  - `name:(str, optional)`: í˜„ì¬ ì§„í–‰í•˜ëŠ” ì‹¤í—˜ ì´ë¦„. (ì‹¤í—˜ ì´ë¦„ ì •ë„ë¡œ ìƒê°í•˜ë©´ ë¨. í•˜ë‚˜ì˜ projectì—ì„œ ë‹¤ì–‘í•œ ì‹¤í—˜ì´ ê°€ëŠ¥í•¨. ì´ê²Œ ì—¬ëŸ¬ ê·¸ë˜í”„ì—ì„œ í•˜ë‚˜ì˜ ìƒ‰ê¹”ì„ ê°€ë¦¬í‚¤ëŠ” idê°€ ë¨)
  - `config:(dict, argparse, absl.flags, str, optional)` : tracking í• ê²ƒë“¤ ì§€ì •  

<p align="center"> <img src="../images/20220517212403.png" width="75%"> </p>

<div align="center" markdown="1"> ìœ„ ê·¸ë¦¼ì—ì„œ ë³¼ ìˆ˜ ìˆë“¯ tableë¡œ í•­ëª©ë“¤ ì‚´í´ë³´ë©´ columnë“¤ì— config í•­ëª©ë“¤ì´ ì¶”ê°€ë˜ì–´ ìˆëŠ”ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.  ì¢Œì¸¡ì˜ clean-sponge-7, playful-brook-5 ë“±ì€ ë™ì¼í•œ repositoryì—ì„œ ì§„í–‰í•œ ì—¬ëŸ¬ ë‹¤ë¥¸ ì‹¤í—˜ ê²°ê³¼ë“¤ì´ë‹¤. 
</div>


```python
def model_pipeline(hyperparameters):

    # tell wandb to get started
    with wandb.init(project="pytorch-demo", config=hyperparameters):    
      # access all HPs through wandb.config, so logging matches execution!
      config = wandb.config

      # make the model, data, and optimization problem
      model, train_loader, test_loader, criterion, optimizer = make(config)
      print(model)

      # and use them to train the model
      train(model, train_loader, criterion, optimizer, config)

      # and test its final performance
      test(model, test_loader)

    return model

def make(config):
    """ Training í•  ë•Œ ë°ì´í„° ì§€ì •í•˜ê³ , setting ì—¬ëŸ¬ê°œ í•˜ëŠ”ê±° ì—¬ê¸°ì„œ ë‹¤ í•˜ëŠ” ëŠë‚Œì„
    ìœ„ì—ì„œ ì§€ì •í•œ í™˜ê²½ì„¤ì • ê´€ë ¨ ë°ì´í„°ê°€ ì—¬ê¸°ì„œ ì´ˆê¸°í™” í•˜ëŠ”ë° í™œìš©ë¨
        
    """    
    # Make the data
    train, test = get_data(train=True), get_data(train=False)
    train_loader = make_loader(train, batch_size=config.batch_size)
    test_loader = make_loader(test, batch_size=config.batch_size)

    # Make the model
    # ìœ„ì—ì„œ ì„¤ì •í•œ kernels, classes ì •ë³´ê°€ ì—¬ê¸°ì„œ ì“°ì„
    model = ConvNet(config.kernels, config.classes).to(device)

    # Make the loss and optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(
        model.parameters(), lr=config.learning_rate)
    
    return model, train_loader, test_loader, criterion, optimizer

def get_data(slice=5, train=True):
    full_dataset = torchvision.datasets.MNIST(root=".",
                                              train=train, 
                                              transform=transforms.ToTensor(),
                                              download=True)
    # equiv to slicing with [::slice] 
    # Dataset í´ë˜ìŠ¤(__getitem__, __len__ì„ ê°€ì§€ëŠ”)ë¥¼ ì—¬ëŸ¬ê°œì˜ í´ë˜ìŠ¤ë¡œ ìª¼ê° ê²ƒìœ¼ë¡œ ë³´ì„
    sub_dataset = torch.utils.data.Subset(
      full_dataset, indices=range(0, len(full_dataset), slice))
    
    return sub_dataset

def make_loader(dataset, batch_size):
    loader = torch.utils.data.DataLoader(dataset=dataset,
                                         batch_size=batch_size, 
                                         shuffle=True,
                                         pin_memory=True, num_workers=2)
    return loader


# Conventional and convolutional neural network

class ConvNet(nn.Module):
    def __init__(self, kernels, classes=10):
        super(ConvNet, self).__init__()
        
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, kernels[0], kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.layer2 = nn.Sequential(
            nn.Conv2d(16, kernels[1], kernel_size=5, stride=1, padding=2),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2))
        self.fc = nn.Linear(7 * 7 * kernels[-1], classes)
        
    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.reshape(out.size(0), -1)
        out = self.fc(out)
        return out
```

### wandb.watch

- `wandb.watch`: torch modelì˜ gradient ë“±ì„ tracking í•˜ê¸°ìœ„í•´ ì‚¬ìš©ë¨
  - ê´€ë ¨ íŒŒë¼ë¯¸í„°
    - `models:(torch.Module, optional)`: pytorch ê¸°ë°˜ ë”¥ëŸ¬ë‹ ëª¨ë¸
    - `criterion:(torch.F, optional)`: loss í•¨ìˆ˜
    - `log(str)`: gradients, parameter ì¤‘ì— í•˜ë‚˜ë¥¼ ê¸°ì… ê°€ëŠ¥í•˜ë©°, allì„ í†µí•´ ë‘˜ ë‹¤ ì¡°íšŒ í•  ìˆ˜ë„ ìˆìŒ

<p align="center"> <img src="../images/20220517212453.png" width="70%"> </p>

<div align="center" markdown="1"> wandb í™ˆí˜ì´ì§€ì—ì„œ gradient, parameter ê´€ë ¨ ê·¸ë˜í”„ ì¡°íšŒ ê°€ëŠ¥ 
</div>

### wandb.log

- `wandb.log`: python dictionary íƒ€ì…ìœ¼ë¡œ ì¸ìë¥¼ ë„˜ê¸°ë©°, wandb í™ˆí˜ì´ì§€ì—ì„œ ê·¸ë˜í”„ë¡œ ì¶œë ¥í•˜ê³  ì‹¶ì€ ê°’ ë“¤ì„ ì ìœ¼ë©´ ë¨
  - ê´€ë ¨ íŒŒë¼ë¯¸í„°
    - `step:(int, optional)`: ëª‡ stepë§ˆë‹¤ ê·¸ë˜í”„ë¡œ ì°ì„ ê²ƒì¸ì§€ ë‚˜íƒ€ëƒ„. ê°’ì´ ì‘ì„ìˆ˜ë¡ ì´˜ì´˜í•œ ê·¸ë˜í”„ê°€ ì™„ì„±ë ê²ƒì„

- wandbì˜ `watch`, `log` í™œìš©ë¨
  - watch: log_freqë§ˆë‹¤ gradient, parameter ë¡œê·¸ ë‚¨ê¸°ëŠ”ë° í™œìš©ë¨
  - log: ë‚˜ë¨¸ì§€ ê°’ë“¤ ë¡œê·¸ ë‚¨ê¸°ëŠ”ë° í™œìš©ë¨


```python
def train(model, loader, criterion, optimizer, config):
    # Tell wandb to watch what the model gets up to: gradients, weights, and more!
    wandb.watch(model, criterion, log="all", log_freq=10)

    # Run training and track with wandb
    total_batches = len(loader) * config.epochs
    example_ct = 0  # number of examples seen
    batch_ct = 0
    for epoch in tqdm(range(config.epochs)):
        for _, (images, labels) in enumerate(loader):

            loss = train_batch(images, labels, model, optimizer, criterion)     # í”íˆ pytorch í”„ë ˆì„ì›Œí¬ì—ì„œ ì“°ì´ëŠ” í•™ìŠµ ë£¨í‹´
            example_ct +=  len(images)
            batch_ct += 1

            # Report metrics every 25th batch
            if ((batch_ct + 1) % 25) == 0:
                train_log(loss, example_ct, epoch)      # gradient, parameterê°€ ì•„ë‹Œ ë‹¤ë¥¸ê°’ë“¤ì„ ì¡°íšŒí•˜ê¸° í•¨ìˆ˜ ì •ì˜ ë° ì‚¬ìš©


def train_batch(images, labels, model, optimizer, criterion):
    images, labels = images.to(device), labels.to(device)
    
    # Forward pass â¡
    outputs = model(images)
    loss = criterion(outputs, labels)
    
    # Backward pass â¬…
    optimizer.zero_grad()
    loss.backward()

    # Step with optimizer
    optimizer.step()

    return loss

def train_log(loss, example_ct, epoch):
    # Where the magic happens
    wandb.log({"epoch": epoch, "loss": loss}, step=example_ct)
    print(f"Loss after " + str(example_ct).zfill(5) + f" examples: {loss:.3f}")
```

### wandb.save

- `wandb.save`: ëª¨ë¸ ê°€ì¤‘ì¹˜, log, ì½”ë“œë“±ì„ ì €ì¥í•  ìˆ˜ ìˆê²Œ í•´ì¤Œ.


```python
def test(model, test_loader):
    model.eval()

    # Run the model on some test examples
    with torch.no_grad():
        correct, total = 0, 0
        for images, labels in test_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

        print(f"Accuracy of the model on the {total} " +
              f"test images: {100 * correct / total}%")
        
        wandb.log({"test_accuracy": correct / total})

    # Save the model in the exchangeable ONNX format
    torch.onnx.export(model, images, "model.onnx")
    wandb.save("model.onnx")
```

- ì‹¤í–‰!

```python
# Build, train and analyze the model with the pipeline
model = model_pipeline(config)
```


    wandb version 0.12.16 is available!  To upgrade, please run:
    $ pip install wandb --upgrade
    Tracking run with wandb version 0.12.11
    Run data is saved locally in <code>d:\Work\Study\wandb\wandb\run-20220517_200748-2gveead3</code>
    Syncing run <strong><a href="https://wandb.ai/javis-team/pytorch-demo/runs/2gveead3" target="_blank">mild-snow-9</a></strong> to <a href="https://wandb.ai/javis-team/pytorch-demo" target="_blank">Weights & Biases</a> (<a href="https://wandb.me/run" target="_blank">docs</a>)<br/>


    ConvNet(
      (layer1): Sequential(
        (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (1): ReLU()
        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (layer2): Sequential(
        (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
        (1): ReLU()
        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (fc): Linear(in_features=1568, out_features=10, bias=True)
    )
    


      0%|          | 0/5 [00:00<?, ?it/s]


    Loss after 03072 examples: 0.470
    Loss after 06272 examples: 0.261
    Loss after 09472 examples: 0.142
    Loss after 12640 examples: 0.113
    Loss after 15840 examples: 0.045
    Loss after 19040 examples: 0.114
    Loss after 22240 examples: 0.046
    Loss after 25408 examples: 0.030
    Loss after 28608 examples: 0.111
    Loss after 31808 examples: 0.060
    Loss after 35008 examples: 0.026
    Loss after 38176 examples: 0.036
    Loss after 41376 examples: 0.048
    Loss after 44576 examples: 0.016
    Loss after 47776 examples: 0.010
    Loss after 50944 examples: 0.016
    Loss after 54144 examples: 0.066
    Loss after 57344 examples: 0.017
    Accuracy of the model on the 2000 test images: 98.05%
    
    

<code markdown='1'>
Waiting for W&B process to finish... <strong style="color:green">(success).</strong>
</code>


    VBox(children=(Label(value='0.001 MB of 0.112 MB uploaded (0.000 MB deduped)\r'), FloatProgress(value=0.008004â€¦



<style>
    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }
    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }
    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }
    </style>
<div class="wandb-row"><div class="wandb-col"><h3>Run history:</h3><br/><table class="wandb"><tr><td>epoch</td><td>â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–†â–†â–†â–†â–ˆâ–ˆâ–ˆ</td></tr><tr><td>loss</td><td>â–ˆâ–…â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–ƒâ–‚â–â–â–‚â–â–â–â–‚â–</td></tr><tr><td>test_accuracy</td><td>â–</td></tr></table><br/></div><div 
class="wandb-col"><h3>Run summary:</h3><br/><table class="wandb"><tr><td>epoch</td><td>4</td></tr><tr><td>loss</td><td>0.01722</td></tr><tr><td>test_accuracy</td><td>0.9805</td></tr></table><br/></div></div>



Synced <strong style="color:#cdcd00">mild-snow-9</strong>: <a href="https://wandb.ai/javis-team/pytorch-demo/runs/2gveead3" target="_blank">https://wandb.ai/javis-team/pytorch-demo/runs/2gveead3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)



Find logs at: <code>.\wandb\run-20220517_200748-2gveead3\logs</code>


- ìœ„ ì¶œë ¥ì„ í†µí•´ ë‚˜ì˜¤ëŠ” ë§í¬ë¥¼ ë“¤ì–´ê°€ë©´ wandbì™€ ì—°ê²°ë˜ë©° webì„ í†µí•´ gradientes, parameters, ì§€ì •í•œ ê°’ ë“¤ì— ëŒ€í•œ ë³€í™”ë„ ë“±ì„ ë³¼ ìˆ˜ ìˆë‹¤


<p align="center">
    <img src="/images/2022-03-20-02-52-20.png" width="90%">
</p>

## Sweapì„ í†µí•œ í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹

[Google Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pytorch/Organizing_Hyperparameter_Sweeps_in_PyTorch_with_W%26B.ipynb#scrollTo=FuTP9WFMSjQP)  

[Sweap ëŒë ¤ë³¼ ìˆ˜ ìˆëŠ” ëª‡ê°€ì§€ ìƒ˜í”Œ ì½”ë“œë“¤](https://github.com/wandb/examples/tree/master/examples/keras/keras-cnn-fashion)